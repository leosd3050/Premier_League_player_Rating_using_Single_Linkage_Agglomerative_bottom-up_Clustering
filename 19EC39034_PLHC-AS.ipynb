{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgl3OO9WXbxl"
      },
      "source": [
        "**Roll**: 19EC39034 \\\n",
        "**Name**: Shaswata Dutta \\\n",
        "**Project Code**: **PLHC-AS** \\\n",
        "**Project Title**: Premier League Player Rating using Single Linkage Agglomerative (Bottom-Up) Clustering Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9LQRhNquRA2"
      },
      "source": [
        "Importing **necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBOX-RbZuL5u"
      },
      "outputs": [],
      "source": [
        "# %%timeit\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import timeit\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLLnNNGmuVQI"
      },
      "source": [
        "### **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brcizzk_uad1",
        "outputId": "583310c2-1313-4437-d5ef-57d23f5f13fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time elapsed for basic preprocessing:  0.03984754200007501 sec\n"
          ]
        }
      ],
      "source": [
        "# %%timeit\n",
        "start_time = timeit.default_timer()\n",
        "data_ = pd.read_csv('ipl.csv').to_numpy()\n",
        "# print(data_.shape[0])\n",
        "lab = data_[:, 0].reshape((data_.shape[0], 1))\n",
        "# print(lab.shape)\n",
        "data = data_[:, 1:]\n",
        "# print(data.shape)\n",
        "# print(data)\n",
        "# print(\"Data type:\", type(data))\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "r, c = data.shape\n",
        "\n",
        "## changing all data types to float except those of missing values\n",
        "for i in range(r):\n",
        "  for j in range(c):\n",
        "    if(data[i][j] == '-'):\n",
        "      continue\n",
        "    else:\n",
        "      data[i][j] = float(data[i][j])\n",
        "\n",
        "## removing those columns having all entries as zeros\n",
        "listcol = []\n",
        "for i in range(c):\n",
        "  cnt = 0\n",
        "  for j in range(r):\n",
        "    if(data[j, i] == 0):\n",
        "      cnt =cnt+1\n",
        "  if(cnt == r):\n",
        "    listcol.append(i)\n",
        "#     print(i)\n",
        "data = np.delete(data, listcol, 1)\n",
        "c = c-len(listcol)\n",
        "\n",
        "print(\"Time elapsed for basic preprocessing: \", elapsed, \"sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYjt9J0EydUl"
      },
      "source": [
        "**DATA IMPUTATION** \\\n",
        "We have used three types of imputations to deal with the missing entries (the ones marked '-', which are of <class 'str'> type): \n",
        " * Regression Imputation\n",
        " * Mean Imputation\n",
        " * Zero Imputation\n",
        "\n",
        "\n",
        "**The required type of imputation to be used can be applied by running any of the following 3 code cells**.\n",
        "\n",
        "**For the report, we have only used Regression Imputation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell implements **Regression Imputation** for the empty values in the dataset."
      ],
      "metadata": {
        "id": "C2eHiieZ614g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e9cKjAt35JcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81e648a-cee3-435d-f86c-ba294b16b557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 1\n",
            "17 1\n",
            "19 1\n",
            "Time elapsed for regression imputation on the entire dataset:  0.014216356000019914 sec\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "def lin_reg(x_, y_):    # function for linear regression weight computation\n",
        "  # we will add an extra 1 for including bias in the weights returned\n",
        "  n = len(x_)\n",
        "  x = np.zeros((n,2))\n",
        "  for i in range(n):\n",
        "    x[i][0] = 1        # adding an extra 1 for incorporating the bias term with the weights\n",
        "    x[i][1] = x_[i]\n",
        "  y = np.array(y_).reshape((n, 1))\n",
        "  amat = np.matmul(np.transpose(x), x)\n",
        "  bmat = np.matmul(np.transpose(x), y)\n",
        "  w = np.matmul(np.linalg.inv(amat), bmat)\n",
        "  return w\n",
        "\n",
        "for j in range(c):\n",
        "  flag = 0\n",
        "  for i in range(r):\n",
        "    if(data[i][j]=='-'):\n",
        "      flag = 1\n",
        "      break\n",
        "  if(flag):\n",
        "    # we will apply regression imputation on all the entries of column j\n",
        "    print(j, flag)\n",
        "    xarr = []\n",
        "    yarr = []\n",
        "    for i in range(r):\n",
        "      if(isinstance(data[i][j], str)):\n",
        "        continue\n",
        "      else:\n",
        "        xarr.append(data[i][j])\n",
        "        yarr.append(i)\n",
        "    warr = lin_reg(xarr, yarr)    # warr is a numpy array\n",
        "    for i in range(r):\n",
        "      if(isinstance(data[i][j], str)):\n",
        "        data[i][j] = warr[0] + warr[1]*i\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Time elapsed for regression imputation on the entire dataset: \", elapsed, \"sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ALTjMjWXbxs"
      },
      "source": [
        "The following cell implements **Mean Imputation** for the empty values in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBz1EZ8H_t2A",
        "outputId": "f5b838c6-b0be-4c45-eabc-164eb85160be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.460000026389025e-05\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "def mean_imput(x_, y_):   # for mean imputation\n",
        "  n = len(x_)\n",
        "  s = 0\n",
        "  for i in x_:\n",
        "    s = s+i\n",
        "  return s/n\n",
        "\n",
        "for j in range(c):\n",
        "  flag = 0\n",
        "  for i in range(r):\n",
        "    if(data[i][j]=='-'):\n",
        "      flag = 1\n",
        "      break\n",
        "  if(flag):\n",
        "    # we will apply mean imputation on all the entries of column j\n",
        "    print(j, flag)\n",
        "    xarr = []\n",
        "    yarr = []\n",
        "    for i in range(r):\n",
        "      if(isinstance(data[i][j], str)):\n",
        "        continue\n",
        "      else\n",
        "        xarr.append(data[i][j])\n",
        "        yarr.append(i)\n",
        "    mu_ = mean_imput(xarr, yarr)\n",
        "    for i in range(r):\n",
        "      if(isinstance(data[i][j], str)):\n",
        "        data[i][j] = mu_    # warr is a numpy array  \n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w78Qj9jsQYFo"
      },
      "source": [
        "The following cell implements **Zero Imputation**, i.e., replaces empty entries with zeros in the given dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fonEw1a7QXF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186a685c-a83b-470f-cde6-1ebb8d1af55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.004130086999964533\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "for i in range(r):\n",
        "  for j in range(c):\n",
        "    if(data[i][j] == '-'):\n",
        "      data[i][j] = float(0.0)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCy5KkDCW3K9"
      },
      "source": [
        "**Checking for any further missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogioeJUy--KK",
        "outputId": "05351a9c-72a6-453d-a974-1af46033b169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No more missing values\n",
            "Time taken for checking any missing values:  0.0038982989999567508 sec\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "  for j in range(c):\n",
        "    if(isinstance(data[i][j],str)):\n",
        "      cnt = cnt+1\n",
        "if(cnt==0):\n",
        "  print(\"No more missing values\")\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Time taken for checking any missing values: \",elapsed,\"sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two cells are for normalizing the entries of the dataset. **For this assignment, we are sticking to normalizing the rows (i.e., the records or samples)**."
      ],
      "metadata": {
        "id": "GECLgd9q89eN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSun7hg5W7tf"
      },
      "source": [
        "Normalizing **only the rows** of the data entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dbezCVLW-Nb",
        "outputId": "d27ca559-3d24-457e-9737-b9c33426a367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time elapsed to normalize the rows of the entire data:  0.003617752999957702 sec\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "for i in range(r):\n",
        "  data[i] /= np.linalg.norm(data[i])\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Time elapsed to normalize the rows of the entire data: \",elapsed,\"sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hyiNXQhhSBo"
      },
      "source": [
        "Normalizing **only the columns** of the data entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bIRz4HL8hT8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe847ef-3f88-4080-ef45-9527f02fa8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00529506600000218\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "for j in range(c):\n",
        "  s = 0\n",
        "  for i in range(r):\n",
        "    s += data[i][j]**2\n",
        "  s = math.sqrt(s)\n",
        "  for i in range(r):\n",
        "    data[i][j] /= s\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTVhxC9kXbxu"
      },
      "source": [
        "### **Step-1** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hio2BMNyXBD"
      },
      "source": [
        "Function for **k-Means Clustering** to be applied on the given dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL9K75mGXbxu",
        "outputId": "e6dba8e5-3fc6-4ad1-e802-2953292fcdf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.000545464999959222\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "def kmeans_cluster(k, randk_, Tmax, data_):\n",
        "  r_, c_ = data_.shape\n",
        "  mu = np.zeros((k, c_)) # numpy array containing means of clusters we are building\n",
        "  for i in range(k):    # initializing the means\n",
        "    for j in range(c_):\n",
        "      mu[i][j] = data_[randk_[i]][j]\n",
        "\n",
        "  cluster = dict()\n",
        "  basket = [[] for mill in range(k)]\n",
        "  curr_basket = basket\n",
        "  for it in range(Tmax):\n",
        "    for i in range(r_):\n",
        "      mindist = np.inf   # for maximum similarity, least distance\n",
        "      muidx = -1\n",
        "      for kup in range(k):\n",
        "        sim_ = float(np.dot(data_[i], mu[kup])/(np.linalg.norm(data_[i])*np.linalg.norm(mu[kup])))\n",
        "        # print(\"sim = \", sim_)\n",
        "        if(sim_ >= 1.0):\n",
        "          sim_ = 1.0\n",
        "        # dist_ = float(math.sqrt(2*(1.0-sim_)))\n",
        "        dist_ = float(1.0-sim_)\n",
        "        if(dist_< mindist):\n",
        "          mindist = dist_\n",
        "          muidx = kup\n",
        "      basket[muidx].append(i)\n",
        "      cluster[i] = muidx\n",
        "    \n",
        "    # computing new means\n",
        "    mu = np.zeros((k, c_))\n",
        "    for kup in range(k):\n",
        "      for id in basket[kup]:\n",
        "        for j_ in range(c_):\n",
        "          mu[kup][j_] = mu[kup][j_] + data_[id][j_]\n",
        "      mu[kup] = mu[kup]/len(basket[kup])\n",
        "    \n",
        "    curr_basket = basket\n",
        "    basket = [[] for mill in range(k)]\n",
        "\n",
        "  return curr_basket, cluster\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I86_VPFKXbxv"
      },
      "source": [
        "### **Step-2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5E-thabXbxv"
      },
      "source": [
        "Function for **Silhouette Score (Coefficient)** computation for the obtained clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P0sTjEBv-Bs",
        "outputId": "acc49dc7-3309-4e14-bec4-d89fc0342cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0008466639999369363\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "def silhouette_score(k, data_, curr_basket_, cluster_):\n",
        "  r_, c_ = data_.shape\n",
        "  sil_sc = np.array([0.0 for i in range(r_)])   # array of silhouette scores for all the r = 143 samples\n",
        "  cntarr = np.array([0 for i in range(k)])\n",
        "  for i in range(r_):\n",
        "    if(len(curr_basket_[cluster_[i]]) == 1):\n",
        "      sil_sc[i] = 0.0\n",
        "      continue\n",
        "    muidx = cluster_[i]\n",
        "    cntarr[muidx] += 1\n",
        "    s1 = 0.0\n",
        "    # print(\"s1 before = \", type(s1))\n",
        "    for id in curr_basket_[muidx]:\n",
        "      if(id!=i):\n",
        "        # print(\"type of dot product: \", type(np.dot(data_[id], data_[i])/(np.linalg.norm(data_[i])*np.linalg.norm(data_[id]))))\n",
        "        sim_ = float(np.dot(data_[id], data_[i])/(np.linalg.norm(data_[i])*np.linalg.norm(data_[id])))\n",
        "        if(sim_ >= 1.0):\n",
        "          sim_ = 1.0\n",
        "        # dist_ = float(math.sqrt(2*(1.0-sim_)))\n",
        "        dist_ = float(1.0-sim_)\n",
        "        s1 = s1 + dist_\n",
        "    # print(\"s1 after adding = \", type(s1))\n",
        "    a = s1/(len(curr_basket_[muidx])-1)\n",
        "    # print(\"a = \", a)\n",
        "    \n",
        "    mins2 = np.inf\n",
        "    cntkup = 0\n",
        "    for kup in range(k):\n",
        "      if(kup != muidx):\n",
        "        cntkup +=1\n",
        "        s2 = 0.0\n",
        "        for id in curr_basket_[kup]:\n",
        "          sim_ = float(np.dot(data_[id], data_[i])/(np.linalg.norm(data_[i])*np.linalg.norm(data_[id])))\n",
        "          if(sim_ >= 1.0):\n",
        "            sim_ = 1.0\n",
        "          # dist_ = float(math.sqrt(2*(1.0-sim_)))\n",
        "          dist_ = float(1.0-sim_)\n",
        "          s2 = s2 + dist_\n",
        "        s2 = s2/len(curr_basket_[kup])\n",
        "        if(s2 < mins2):\n",
        "          mins2 = s2\n",
        "    b = mins2\n",
        "    sil_sc[i] = (b-a)/max(a, b)\n",
        "  \n",
        "  return sil_sc\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER-1keqiXbxv"
      },
      "source": [
        "#### The following cell implements **Step 1 and Step 2 together, for $k = 3$**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH-3JRzsXbxv",
        "outputId": "aeb6afd8-df79-4a3c-b97d-bea1e63bbcab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting indices: [ 50 109 112]\n",
            "Time elapsed for kmeans clustering:  0.28588430999843695 \n",
            "\n",
            "Length of cluster 0 =  60\n",
            "Length of cluster 1 =  69\n",
            "Length of cluster 2 =  14\n",
            "\n",
            "\n",
            "Time elapsed for computing Silhouette Coefficient:  0.40547618599885027\n",
            "Silhouette Coefficient =  0.743572331759283\n",
            "Time elapsed for saving as a text file ('kmeans.txt'):  0.001441120999515988\n",
            "Total time for this cell:  0.6964116169983754\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "ts = start_time\n",
        "k = 3\n",
        "Tmax = 20\n",
        "randk = np.unique(np.random.choice(r, k, replace=False))   # array of k random starting seed indices \n",
        "print(\"Starting indices:\", randk)\n",
        "curr_basket, cluster = kmeans_cluster(k, randk, Tmax, data) # kmeans clustering done\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Time elapsed for kmeans clustering: \", elapsed,'\\n')\n",
        "# curr_basket.sort()\n",
        "for kup in range(k):\n",
        "#     curr_basket[kup].sort()\n",
        "    print(\"Length of cluster\",str(kup),\"= \", len(curr_basket[kup]))\n",
        "# print(curr_basket)\n",
        "print('\\n')\n",
        "start_time = timeit.default_timer()\n",
        "silhouette_arr = silhouette_score(k, data, curr_basket, cluster)\n",
        "sil_sc = np.mean(silhouette_arr)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Time elapsed for computing Silhouette Coefficient: \", elapsed)\n",
        "print(\"Silhouette Coefficient = \",sil_sc)\n",
        "\n",
        "start_time = timeit.default_timer()\n",
        "curr_basket.sort()\n",
        "s1 = ''\n",
        "for i in range(k):\n",
        "    curr_basket[i].sort()\n",
        "    l = len(curr_basket[i])\n",
        "    for j in range(l-1):\n",
        "        s1 = s1 + str(curr_basket[i][j])+','\n",
        "    s1 = s1 + str(curr_basket[i][l-1])+'\\n'\n",
        "# print(s1)\n",
        "with open(\"kmeans_k=3.txt\", \"w\") as f:\n",
        "    f.write(s1)\n",
        "f.close()\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Time elapsed for saving as a text file ('kmeans.txt'): \", elapsed)\n",
        "\n",
        "cluster_3 = cluster\n",
        "curr_basket_3 = curr_basket   ## we are saving the current clustering as curr_basket_3 \n",
        "                              ## so that we can use it in step 4 if k=3 is optimal no of clusters\n",
        "print(\"Total time for this cell: \", timeit.default_timer() - ts)                    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBI28FEEXbxv"
      },
      "source": [
        "### **Step-3 : Finding optimal $k$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Brdzy5sXbxw"
      },
      "source": [
        "The following cell implements k-Means Clustering and computes the corresponding Silhouette coefficient on the given data.\\\n",
        "For each value of $k$ ($k \\in [3, 4, 5, 6]$), we perform 25 experiments; where each experiment generates a random set of $k$ indices and applies *kmeans_cluster()* function on the dataset to cluster them using the Lloyd's algorithm, and then the *silhouette_score()* function computes the Silhouette score and coefficient (**SC**) for this clustering. \\\n",
        "The value of $k$ for which the SC coefficient is highest, is chosen as the optimal $k$ (to be used in Step 4). \\\n",
        "If the optimal $k$ is greater than $3$, we can uncomment the statements in the following code cell after printing *optk*, and thus the corresponding best clustering can be saved for later use. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8nmiD6nC564",
        "outputId": "c38632cc-a220-4af0-ad4a-ff75cb4615d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time elapsed for 25 experiments for k = 3 :  17.92366932799996\n",
            "Mean Silhouette Coefficient (SC) for k = 3 over 25 runs:  0.6672782988299617\n",
            "Time elapsed for 25 experiments for k = 4 :  20.10370742499981\n",
            "Mean Silhouette Coefficient (SC) for k = 4 over 25 runs:  0.6297204526544806\n",
            "Time elapsed for 25 experiments for k = 5 :  22.169331929000236\n",
            "Mean Silhouette Coefficient (SC) for k = 5 over 25 runs:  0.6314927049577947\n",
            "Time elapsed for 25 experiments for k = 6 :  23.741074625999772\n",
            "Mean Silhouette Coefficient (SC) for k = 6 over 25 runs:  0.6179084279443592\n",
            "Optimal k = 3\n"
          ]
        }
      ],
      "source": [
        "## currently we are normalizing each row\n",
        "karr = [3, 4, 5, 6]\n",
        "Tmax = 20\n",
        "nexp = 25\n",
        "optk = -1\n",
        "bestsc = -1\n",
        "for k in karr:\n",
        "  start_time = timeit.default_timer()\n",
        "  mean_sil_score = 0.0\n",
        "  for exp in range(nexp):\n",
        "    randk = np.unique(np.random.choice(r, k, replace=False))   # array of k random starting seed indices \n",
        "    \n",
        "    curr_basket, cluster = kmeans_cluster(k, randk, Tmax, data)  # performing kmeans\n",
        "    \n",
        "    silhouette_arr = silhouette_score(k, data, curr_basket, cluster) # computing the array of silhouette scores\n",
        "    sil_sc = np.mean(silhouette_arr)\n",
        "    \n",
        "    mean_sil_score += float(1.0*sil_sc)\n",
        "  mean_sil_score /= nexp\n",
        "\n",
        "  elapsed = timeit.default_timer() - start_time\n",
        "    \n",
        "  print(\"Time elapsed for\",str(nexp),\"experiments for k =\",str(k),\": \",elapsed)\n",
        "  if(bestsc < mean_sil_score):\n",
        "    bestsc = mean_sil_score\n",
        "    optk = k\n",
        "  \n",
        "  print(\"Mean Silhouette Coefficient (SC) for k =\", str(k),\"over\", str(nexp), \"runs: \", mean_sil_score)\n",
        "\n",
        "print(\"Optimal k =\",optk)\n",
        "# print(\"For this optimal k, we will save the clustering information in a file ('kmeans.txt')\\n\")\n",
        "\n",
        "# start_time = timeit.default_timer()\n",
        "# randk = np.unique(np.random.choice(r, optk, replace=False))   # array of k random starting seed indices \n",
        "# # print(\"Starting indices:\", randk)\n",
        "# curr_basket, cluster = kmeans_cluster(optk, randk, Tmax, data)\n",
        "# curr_basket.sort()\n",
        "# s1 = ''\n",
        "# for i in range(optk):\n",
        "#     l = len(curr_basket[i])\n",
        "#     for j in range(l-1):\n",
        "#         s1 = s1 + str(curr_basket[i][j])+','\n",
        "#     s1 = s1 + str(curr_basket[i][l-1])+'\\n'\n",
        "# print(s1)\n",
        "# with open(\"kmeans.txt\", \"w\") as f:\n",
        "#     f.write(s1)\n",
        "# f.close()\n",
        "# elapsed = timeit.default_timer() - start_time\n",
        "# print(\"Time elapsed for clustering, and then saving as a text file ('kmeans.txt'): \", elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step - 4: Hierarchical Clustering (Single Linkage Agglomerative (Bottom-Up))**"
      ],
      "metadata": {
        "id": "IjyoJccgjLBa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZGsdTgeXbxw"
      },
      "source": [
        "Function to compute **Single Linkage distance** between two clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0dHO82zA7jy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95c6107-0c85-4d7c-f926-1218af3c3027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0002365909995205584\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "def calsingledist(dat, arr1, arr2):     ## computes single linkage distance between two clusters\n",
        "  mindist2 = np.inf\n",
        "  for x1 in arr1:\n",
        "    for x2 in arr2:\n",
        "      dist2 = float(1.0-float(np.dot(dat[x1], dat[x2])/(np.linalg.norm(dat[x1])*np.linalg.norm(dat[x2]))))\n",
        "      if (mindist2 > dist2):\n",
        "        mindist2 = dist2\n",
        "  return mindist2\n",
        "\n",
        "# def calcompletedist(dat, arr1, arr2):   ## computes complete linkage distance between two clusters \n",
        "#   maxdist2 = -1\n",
        "#   for x1 in arr1:\n",
        "#     for x2 in arr2:\n",
        "#       dist2 = float(math.sqrt(2*1.0-float(np.dot(dat[x1], dat[x2])/(np.linalg.norm(dat[x1])*np.linalg.norm(dat[x2])))))\n",
        "#       if (maxdist2 < dist2):\n",
        "#         maxdist2 = dist2\n",
        "#   return maxdist2\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVuH1Os_8rJq"
      },
      "source": [
        "The following code cell is a function for **Single-Linkage Agglomerative (Bottom-Up) Clustering Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5br8ulXt2F6N",
        "outputId": "a9237b66-58d2-4a11-b3f7-b19a7182c7de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00035450300038064597\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "def bottom_up_single_linkage(k, data_):\n",
        "  r_, c_ = data_.shape\n",
        "  curr = r # current number of clusters, initialized to 143\n",
        "  # print(\"Initial number of clusters = \", curr)\n",
        "  clust = [[i] for i in range(r_)]\n",
        "  # random.shuffle(clust)\n",
        "  # print(\"The initial clusters are: \", clust)\n",
        "  while(curr > k):    # k is the number of clusters at which we should stop\n",
        "    distmin = np.inf\n",
        "    c1 = -1\n",
        "    c2 = -1           # c1 and c2 are indices for which two clusters are getting combined\n",
        "    for i in range(curr):\n",
        "      for j in range(i+1, curr):\n",
        "        # we have singled out two clusters\n",
        "        # now we find the minimum distance between them\n",
        "        # i.e., w.r.t, cosine similarity, what is the maximum similarity we can have for two clusters\n",
        "        # print(i, j)\n",
        "        dist3 = calsingledist(data_, clust[i], clust[j])\n",
        "        if(dist3 < distmin):\n",
        "          distmin = dist3\n",
        "          c1 = i\n",
        "          c2 = j\n",
        "    # print(\"hello!!\")\n",
        "    # print(\"Current no of clusters curr)\n",
        "    clust[c1] = clust[c1] + clust[c2]\n",
        "    clust.pop(c2)\n",
        "    curr = curr-1\n",
        "  return clust\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the *bottom_up_single_linkage()* function for performing the Hierarchical clustering for optimal value of $k$**"
      ],
      "metadata": {
        "id": "4pSs7NSCkpH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWwY_IwSXbxx",
        "outputId": "7ca78932-d555-4cdc-87dc-c235938ef54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample split for k = 3 : 130 6 7 \n",
            "\n",
            "29.25832234599966\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "# k = optk\n",
        "clust_hier = bottom_up_single_linkage(optk, data)\n",
        "print(\"Sample split for k =\", str(k),\": \", end='')\n",
        "for i in range(len(clust_hier)):\n",
        "  print(len(clust_hier[i]),end=' ')\n",
        "print('\\n')\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8ikfjWwXbxx"
      },
      "source": [
        "The following cell is for computing the Jaccard Similarity Score between the cluster sets computed using **k-Means Algorithm**, and the cluster sets computed using **Agglomerative (Bottom-Up) Single-Linkage hierarchical clustering algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSnoW4Oj9skp",
        "outputId": "3c9df768-4fdc-4211-e95d-1542f46fcf21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0013405820000116364\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "best_k = optk\n",
        "## Now given clust and curr-basket\n",
        "## we have to compute the jaccard similarity between different sets\n",
        "## clustered by the two algorithms\n",
        "def jaccard_score(k, curr_basket_, clust_hier_):\n",
        "  clustmap = dict()\n",
        "  clust_score = dict()\n",
        "  indarr = []\n",
        "  for i in range(k):   # initializing the setwise mapping to -1 for all sets\n",
        "    clustmap[i] = -1\n",
        "  for i in range(k):\n",
        "    basket = curr_basket_[i]\n",
        "    maxjs = -1\n",
        "    maxind = -1\n",
        "    for j in range(k):\n",
        "      if(j not in indarr):\n",
        "        cl = clust_hier_[j]\n",
        "        tmp1 = set(basket)\n",
        "        tmp2 = set(cl)\n",
        "        js = len(tmp1.intersection(tmp2))/len(tmp1.union(tmp2))\n",
        "        if(js > maxjs):\n",
        "          maxjs = js\n",
        "          maxind = j\n",
        "    indarr.append(maxind)\n",
        "    clustmap[i] = maxind\n",
        "    clust_score[i] = maxjs\n",
        "  return clustmap, clust_score\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5apQMErFXbxy"
      },
      "source": [
        "The following is **Jaccard Similarity score comparison** for k-Means and Bottom Up Single Linkage clustering. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDSkk0caXbxy",
        "outputId": "c7c81827-7dc3-4ff0-8b3d-f7e89ac6f561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Map:  {0: 0, 1: 1, 2: 2}\n",
            "Jaccard Score recorded:  {0: 0.4580152671755725, 1: 0.0, 2: 0.5}\n",
            "0.017025641999680374\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "## Now given cluster_3 and curr_basket_3\n",
        "## we have to compute the jaccard similarity between different sets\n",
        "## clustered by the two algorithms\n",
        "best_k = optk\n",
        "clust_hier.sort()\n",
        "clustermap, jmap = jaccard_score(best_k, curr_basket_3, clust_hier)  ## computation of Jaccard Score\n",
        "print(\"Cluster Map: \", clustermap)\n",
        "print(\"Jaccard Score recorded: \", jmap)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the cluster information from **Agglomerative Clustering** to ***agglomerative.txt***"
      ],
      "metadata": {
        "id": "x0MTuYi8U4c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts = timeit.default_timer()\n",
        "s1 = ''\n",
        "clust_hier.sort()\n",
        "for i in range(k):\n",
        "    clust_hier[i].sort()\n",
        "    l = len(clust_hier[i])\n",
        "    for j in range(l-1):\n",
        "        s1 = s1 + str(clust_hier[i][j])+','\n",
        "    s1 = s1 + str(clust_hier[i][l-1])+'\\n'\n",
        "# print(s1)\n",
        "with open(\"agglomerative.txt\", \"w\") as f:\n",
        "    f.write(s1)\n",
        "f.close()\n",
        "print(\"Time taken to save hierarchical clustering to text file: \", timeit.default_timer() - ts,\"sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRANMJ4iU3xx",
        "outputId": "52a37da6-6cf0-48f5-af21-506eeacd7bcb"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to save hierarchical clustering to text file:  0.0031453900000997237 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell was used to test the implementation of the Bottom-Up Single Linkage algorithm using *sklearn*"
      ],
      "metadata": {
        "id": "3Ll2AhrIVuOs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjaXO4pAXbxy",
        "outputId": "f092221d-7e8c-4272-c50a-6ff7132c48be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgglomerativeClustering(linkage='single', metric='cosine', n_clusters=3)\n",
            "<class 'numpy.ndarray'>\n",
            "[130, 7, 6]\n"
          ]
        }
      ],
      "source": [
        "# from sklearn.cluster import AgglomerativeClustering\n",
        "# # import numpy as np\n",
        "# X = data\n",
        "# n_clust = optk\n",
        "# clustering = AgglomerativeClustering(n_clusters = n_clust, linkage = \"single\", metric=\"cosine\").fit(X)\n",
        "# print(clustering)\n",
        "# # AgglomerativeClustering()\n",
        "# print(type(clustering.labels_))\n",
        "# # array([1, 1, 1, 0, 0, 0])\n",
        "\n",
        "# cnt = [0 for kup in range(n_clust)]\n",
        "# n = len(clustering.labels_)\n",
        "# for i in range(n):\n",
        "#   cnt[clustering.labels_[i]] += 1\n",
        "# print(cnt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9PvUn85Xbxz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}